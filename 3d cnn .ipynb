{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":9465080,"sourceType":"datasetVersion","datasetId":5755050}],"dockerImageVersionId":30763,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import cv2\nimport os\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\n\n# for videos load \ndef load_videos(video_dir, frame_size=(64, 64), max_frames=60):\n    video_data = []\n    labels = []\n    \n    for label_dir in os.listdir(video_dir):\n        label_path = os.path.join(video_dir, label_dir)\n        if os.path.isdir(label_path):\n            label = label_dir\n            for video_file in os.listdir(label_path):\n                video_path = os.path.join(label_path, video_file)\n                cap = cv2.VideoCapture(video_path)\n                frames = []\n                \n                while len(frames) < max_frames:\n                    ret, frame = cap.read()\n                    if not ret:\n                        break\n                    frame = cv2.resize(frame, frame_size)\n                    frames.append(frame)\n                \n                cap.release()\n                \n                while len(frames) < max_frames:\n                    frames.append(np.zeros((frame_size[0], frame_size[1], 3), dtype=np.uint8))\n                \n                video_data.append(np.array(frames))\n                labels.append(label)\n\n    return np.array(video_data), np.array(labels)\n\nvideo_dir = '/kaggle/input/cricket'  \nX, y = load_videos(video_dir)\n\n# Preprocess labels\nlabel_encoder = LabelEncoder()\ny_encoded = label_encoder.fit_transform(y)\n\nX = X / 255.0\n\n# Split the dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n\n#the 3D CNN model\nmodel = models.Sequential()\n\nmodel.add(layers.Conv3D(32, (3, 3, 3), activation='relu', input_shape=(60, 64, 64, 3)))\nmodel.add(layers.MaxPooling3D((2, 2, 2)))\n\nmodel.add(layers.Conv3D(64, (3, 3, 3), activation='relu'))\nmodel.add(layers.MaxPooling3D((2, 2, 2)))\n\nmodel.add(layers.Conv3D(128, (3, 3, 3), activation='relu'))\nmodel.add(layers.MaxPooling3D((2, 2, 2)))\n\nmodel.add(layers.Flatten())\n\nmodel.add(layers.Dense(512, activation='relu'))\nmodel.add(layers.Dropout(0.5))  # Dropout for regularization\n\nmodel.add(layers.Dense(len(label_encoder.classes_), activation='softmax'))\n\n# Compile the model\nmodel.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\nmodel.summary()\n\n# Train the model\nhistory = model.fit(X_train, y_train, epochs=1, validation_data=(X_test, y_test))\n\ntest_loss, test_acc = model.evaluate(X_test, y_test)\nprint(f\"Test Accuracy: {test_acc}\")\n\n# classification Report\ny_pred = model.predict(X_test)\ny_pred_classes = np.argmax(y_pred, axis=1)\nprint(classification_report(y_test, y_pred_classes, target_names=label_encoder.classes_))\n\nmodel.save('video_classification_3dcnn_model.h5')\n\n# function to classify new videos\ndef classify_video(video_path, model, label_encoder, frame_size=(64, 64), max_frames=60):\n    cap = cv2.VideoCapture(video_path)\n    frames = []\n    \n    while len(frames) < max_frames:\n        ret, frame = cap.read()\n        if not ret:\n            break\n        frame = cv2.resize(frame, frame_size)\n        frames.append(frame)\n    \n    cap.release()\n    \n    while len(frames) < max_frames:\n        frames.append(np.zeros((frame_size[0], frame_size[1], 3), dtype=np.uint8))\n    \n    frames = np.array(frames) / 255.0\n    frames = np.expand_dims(frames, axis=0) \n    \n    predictions = model.predict(frames)\n    predicted_class = np.argmax(predictions, axis=1)\n    \n    return label_encoder.inverse_transform(predicted_class)[0]\n\n# example\nvideo_path = '/kaggle/input/cricket/Right Arm off Spin/101.mp4' \npredicted_label = classify_video(video_path, model, label_encoder)\nprint(f'Predicted label: {predicted_label}')\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-03T17:43:38.179445Z","iopub.execute_input":"2024-10-03T17:43:38.180572Z"},"trusted":true},"execution_count":null,"outputs":[]}]}